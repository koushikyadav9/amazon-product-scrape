{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53de56a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Scraping page 8\n",
      "Scraping page 9\n",
      "Scraping page 10\n",
      "Scraping page 11\n",
      "Scraping page 12\n",
      "Scraping page 13\n",
      "Scraping page 14\n",
      "Scraping page 15\n",
      "Scraping page 16\n",
      "Scraping page 17\n",
      "Scraping page 18\n",
      "Scraping page 19\n",
      "Scraping page 20\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Function to scrape product listing page\n",
    "def scrape_product_listing(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    products = soup.find_all('div', {'data-component-type': 's-search-result'})\n",
    "\n",
    "    for product in products:\n",
    "        # Extract product information\n",
    "        product_url_elem = product.find('a', {'class': 'a-link-normal a-text-normal'})\n",
    "        if product_url_elem:\n",
    "            product_url = 'https://www.amazon.in' + product_url_elem['href']\n",
    "        else:\n",
    "            product_url = 'Not available'\n",
    "        \n",
    "        product_name_elem = product.find('span', {'class': 'a-size-medium a-color-base a-text-normal'})\n",
    "        product_name = product_name_elem.text if product_name_elem else 'Not available'\n",
    "        \n",
    "        product_price_elem = product.find('span', {'class': 'a-price-whole'})\n",
    "        product_price = product_price_elem.text if product_price_elem else 'Not available'\n",
    "\n",
    "        rating_elem = product.find('span', {'class': 'a-icon-alt'})\n",
    "        rating = rating_elem.text.split()[0] if rating_elem else 'Not available'\n",
    "\n",
    "        reviews_elem = product.find('span', {'class': 'a-size-base'})\n",
    "        reviews = reviews_elem.text if reviews_elem else '0'\n",
    "\n",
    "        # Create a dictionary to store the product information\n",
    "        product_data = {\n",
    "            'Product URL': product_url,\n",
    "            'Product Name': product_name,\n",
    "            'Product Price': product_price,\n",
    "            'Rating': rating,\n",
    "            'Number of Reviews': reviews\n",
    "        }\n",
    "\n",
    "        # Append the product data to the CSV file\n",
    "        with open('product_data.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=product_data.keys())\n",
    "            writer.writerow(product_data)\n",
    "\n",
    "# Main scraping logic\n",
    "base_url = 'https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2C283&ref=sr_pg_'\n",
    "num_pages = 20\n",
    "num_products_per_page = 10\n",
    "\n",
    "# Create the CSV file and write the header row\n",
    "with open('product_data.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Product URL', 'Product Name', 'Product Price', 'Rating', 'Number of Reviews'])\n",
    "\n",
    "for page in range(1, num_pages + 1):\n",
    "    url = base_url + str(page)\n",
    "    print('Scraping page', page)\n",
    "    scrape_product_listing(url)\n",
    "\n",
    "    if (page * num_products_per_page) > 200:\n",
    "        break\n",
    "\n",
    "# URLs received in the above case\n",
    "product_urls = [\n",
    "    # List of product URLs\n",
    "]\n",
    "\n",
    "# Function to scrape individual product page\n",
    "def scrape_product_page(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract product information\n",
    "    product_description = soup.find('div', {'id': 'productDescription'}).text.strip()\n",
    "    asin = soup.find('th', text='ASIN').find_next_sibling('td').text.strip()\n",
    "    manufacturer = soup.find('th', text='Manufacturer').find_next_sibling('td').text.strip()\n",
    "\n",
    "    # Print additional product information\n",
    "    print('Product Description:', product_description)\n",
    "    print('ASIN:', asin)\n",
    "    print('Manufacturer:', manufacturer)\n",
    "    print('---')\n",
    "\n",
    "for url in product_urls:\n",
    "    print('Scraping product page:', url)\n",
    "    scrape_product_page(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ffeadd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3e67c272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [03:00<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "base_url = 'https://www.amazon.in/s'\n",
    "params = {\n",
    "    'k': 'bags',\n",
    "    'crid': '2M096C61O4MLT',\n",
    "    'qid': '1653308124',\n",
    "    'sprefix': 'ba,aps,283',\n",
    "    'ref': 'sr_pg_'\n",
    "}\n",
    "\n",
    "product_count = 0\n",
    "total_pages = 200\n",
    "\n",
    "product_links = list()\n",
    "product_names = list()\n",
    "product_prices = list()\n",
    "product_reviews = list()\n",
    "product_ratings = list()\n",
    "for page in tqdm(range(1, total_pages + 1)):\n",
    "    params['ref'] = 'sr_pg_' + str(page)\n",
    "    response = requests.get(base_url, params=params)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    product_list = soup.find_all('div', {'data-component-type': 's-search-result'})\n",
    "\n",
    "    for product in product_list:\n",
    "        product_url = 'https://www.amazon.in' + product.find('a', {'class': 'a-link-normal'})['href']\n",
    "        product_name = product.find('span', {'class': 'a-size-medium'}).text.strip()\n",
    "        product_price = product.find('span', {'class': 'a-price-whole'}).text.replace(',', '')\n",
    "        rating = product.find('span', {'class': 'a-icon-alt'}).text.split()[0]\n",
    "        num_reviews = product.find('span', {'class': 'a-size-base'}).text.replace(',', '')\n",
    "        product_links.append(product_url)\n",
    "        product_names.append(str(product_name))\n",
    "        product_prices.append(product_price)\n",
    "        product_reviews.append(num_reviews)\n",
    "        product_ratings.append(rating)\n",
    "        \n",
    "        product_count += 1\n",
    "        if product_count >= 250:\n",
    "            break\n",
    "\n",
    "        \n",
    "        # function calls to display all necessary product information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "88fbe223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3934f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (len(product_links) == len(product_names) == len(product_prices) == len(product_reviews) == len(product_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e4196743",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {\n",
    "    \"product_url\":product_links,\n",
    "    \"product_name\":product_names,\n",
    "    \"product_price\":product_prices,\n",
    "    \"product_rating\":product_ratings,\n",
    "    \"product_reviews\":product_reviews,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e9829fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(my_dict).to_csv(\"product_info.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
